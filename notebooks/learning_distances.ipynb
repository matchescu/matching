{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Learning String Similarity\n",
    "\n",
    "The paper [@bilenko2002learning] outlines a process by which we can learn the\n",
    "edit distance between two strings using minimal training over pairs of\n",
    "coreferent strings.\n",
    "Coreferent strings are strings that belong to entity references that refer to\n",
    "the same real world object.\n",
    "The idea is that if we fine tune the algorithm that computes the string edit\n",
    "distance to the business domain where we perform entity resolution, we will be\n",
    "able to identify coreferent entity references more accurately than if we use\n",
    "a generic edit distance.\n",
    "The aforementioned paper references an algorithm [@ristad1998learning] which\n",
    "learns to compute the Levenshtein distance between two strings from training\n",
    "data.\n",
    "\n",
    "This notebook showcases Ristad and Yianilos' algorithm using Milenko's approach\n",
    "to constructing the training corpus. "
   ],
   "id": "b9239db8823ba023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:24:21.639188Z",
     "start_time": "2024-10-15T14:24:21.230652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from matchescu.matching.similarity import LevenshteinLearner\n",
    "\n",
    "\n",
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "CSV_PATH = os.path.join(DATADIR, \"cora\", \"cora.csv\")"
   ],
   "id": "9bcd2799fcf96fd9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:24:21.647749Z",
     "start_time": "2024-10-15T14:24:21.640747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pl.read_csv(CSV_PATH, has_header=False, ignore_errors=True).rename({\n",
    "    \"column_1\": \"id\",\n",
    "    \"column_3\": \"class\",\n",
    "    \"column_4\": \"author\",\n",
    "    \"column_5\": \"volume\",\n",
    "    \"column_6\": \"title\",\n",
    "    \"column_7\": \"institution\",\n",
    "    \"column_8\": \"venue\",\n",
    "    \"column_11\": \"year\"\n",
    "}).select(pl.col(\"id\", \"class\", \"author\", \"title\", \"venue\", \"year\"))\n",
    "display(df)"
   ],
   "id": "b9741bb63d0c5d05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1_293, 6)\n",
       "┌──────┬────────────────┬─────────────────────┬─────────────────────┬────────────────────┬─────────┐\n",
       "│ id   ┆ class          ┆ author              ┆ title               ┆ venue              ┆ year    │\n",
       "│ ---  ┆ ---            ┆ ---                 ┆ ---                 ┆ ---                ┆ ---     │\n",
       "│ i64  ┆ str            ┆ str                 ┆ str                 ┆ str                ┆ str     │\n",
       "╞══════╪════════════════╪═════════════════════╪═════════════════════╪════════════════════╪═════════╡\n",
       "│ 1    ┆ blum1993       ┆ avrim blum, merrick ┆ cryptographic       ┆ in pre-proceedings ┆ 1993    │\n",
       "│      ┆                ┆ furst, mic…         ┆ primitives based…   ┆ of crypto '…       ┆         │\n",
       "│ 2    ┆ blum1993       ┆ avrim blum, merrick ┆ cryptographic       ┆ proc. crypto 93,   ┆ 1994    │\n",
       "│      ┆                ┆ furst, mic…         ┆ primitives based…   ┆                    ┆         │\n",
       "│ 3    ┆ blum1993       ┆ a. blum, m. furst,  ┆ cryptographic       ┆ crypto,            ┆ 1993    │\n",
       "│      ┆                ┆ m. kearns, …        ┆ primitives based…   ┆                    ┆         │\n",
       "│ 4    ┆ blum1994       ┆ blum, a., furst,    ┆ weakly learning dnf ┆ proceedings of the ┆ (1994). │\n",
       "│      ┆                ┆ m., jackson, …      ┆ and charac…         ┆ 26th annual…       ┆         │\n",
       "│ 5    ┆ blum1994       ┆ blum, a., furst,    ┆ weakly learning dnf ┆ in proceedings of  ┆ (1994). │\n",
       "│      ┆                ┆ m., jackson, …      ┆ and charac…         ┆ the twenty-s…      ┆         │\n",
       "│ …    ┆ …              ┆ …                   ┆ …                   ┆ …                  ┆ …       │\n",
       "│ 1289 ┆ schapire1998   ┆ robert e. schapire  ┆ improved boosting   ┆ in proceedings of  ┆ 1998    │\n",
       "│      ┆                ┆ and yoram s…        ┆ algorithms u…       ┆ the eleventh…      ┆         │\n",
       "│ 1290 ┆ schapire       ┆ schapire, r. e.,    ┆ boosting the        ┆ null               ┆ (1998). │\n",
       "│      ┆                ┆ freund, y., b…      ┆ margin: a new exp…  ┆                    ┆         │\n",
       "│ 1291 ┆ schapire1998mm ┆ robert e. schapire  ┆ a system for        ┆ unpublished        ┆ 1998    │\n",
       "│      ┆                ┆ and yoram s…        ┆ multiclass multi-…  ┆ manuscript,        ┆         │\n",
       "│ 1292 ┆ singer         ┆ robert e. schapire  ┆ improved boosting   ┆ null               ┆ null    │\n",
       "│      ┆                ┆ yoram singe…        ┆ algorithms u…       ┆                    ┆         │\n",
       "│ 1293 ┆ singer         ┆ robert e. schapire  ┆ improved boosting   ┆ null               ┆ null    │\n",
       "│      ┆                ┆ yoram singe…        ┆ algorithms u…       ┆                    ┆         │\n",
       "└──────┴────────────────┴─────────────────────┴─────────────────────┴────────────────────┴─────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_293, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>class</th><th>author</th><th>title</th><th>venue</th><th>year</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;blum1993&quot;</td><td>&quot;avrim blum, merrick furst, mic…</td><td>&quot;cryptographic primitives based…</td><td>&quot;in pre-proceedings of crypto &#x27;…</td><td>&quot;1993&quot;</td></tr><tr><td>2</td><td>&quot;blum1993&quot;</td><td>&quot;avrim blum, merrick furst, mic…</td><td>&quot;cryptographic primitives based…</td><td>&quot;proc. crypto 93,&quot;</td><td>&quot;1994&quot;</td></tr><tr><td>3</td><td>&quot;blum1993&quot;</td><td>&quot;a. blum, m. furst, m. kearns, …</td><td>&quot;cryptographic primitives based…</td><td>&quot;crypto,&quot;</td><td>&quot;1993&quot;</td></tr><tr><td>4</td><td>&quot;blum1994&quot;</td><td>&quot;blum, a., furst, m., jackson, …</td><td>&quot;weakly learning dnf and charac…</td><td>&quot;proceedings of the 26th annual…</td><td>&quot;(1994).&quot;</td></tr><tr><td>5</td><td>&quot;blum1994&quot;</td><td>&quot;blum, a., furst, m., jackson, …</td><td>&quot;weakly learning dnf and charac…</td><td>&quot;in proceedings of the twenty-s…</td><td>&quot;(1994).&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1289</td><td>&quot;schapire1998&quot;</td><td>&quot;robert e. schapire and yoram s…</td><td>&quot;improved boosting algorithms u…</td><td>&quot;in proceedings of the eleventh…</td><td>&quot;1998&quot;</td></tr><tr><td>1290</td><td>&quot;schapire&quot;</td><td>&quot;schapire, r. e., freund, y., b…</td><td>&quot;boosting the margin: a new exp…</td><td>null</td><td>&quot;(1998).&quot;</td></tr><tr><td>1291</td><td>&quot;schapire1998mm&quot;</td><td>&quot;robert e. schapire and yoram s…</td><td>&quot;a system for multiclass multi-…</td><td>&quot;unpublished manuscript,&quot;</td><td>&quot;1998&quot;</td></tr><tr><td>1292</td><td>&quot;singer&quot;</td><td>&quot;robert e. schapire yoram singe…</td><td>&quot;improved boosting algorithms u…</td><td>null</td><td>null</td></tr><tr><td>1293</td><td>&quot;singer&quot;</td><td>&quot;robert e. schapire yoram singe…</td><td>&quot;improved boosting algorithms u…</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:24:27.809894Z",
     "start_time": "2024-10-15T14:24:21.648638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "records = list(df.iter_rows(named=True))\n",
    "dedupe_data = []\n",
    "y = []\n",
    "for i, left_record in enumerate(records):\n",
    "    for j, right_record in enumerate(records, i+1):\n",
    "        lclass, rclass = left_record[\"class\"], right_record[\"class\"]\n",
    "        row = {f\"{k}_left\": v for k,v in left_record.items()}\n",
    "        row.update(\n",
    "            {f\"{k}_right\": v for k,v in right_record.items()}\n",
    "        )\n",
    "        dedupe_data.append(row)\n",
    "        y.append(int(lclass == rclass))\n",
    "X = pl.DataFrame(dedupe_data).to_numpy()\n",
    "y = np.array(y)\n",
    "display(X, y)"
   ],
   "id": "7cfc4cd52f58e38c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'blum1993',\n",
       "        'avrim blum, merrick furst, michael kearns, and richard j. lipton.',\n",
       "        ..., 'cryptographic primitives based on hard learning problems.',\n",
       "        \"in pre-proceedings of crypto '93,\", '1993'],\n",
       "       [1, 'blum1993',\n",
       "        'avrim blum, merrick furst, michael kearns, and richard j. lipton.',\n",
       "        ..., 'cryptographic primitives based on hard learning problems.',\n",
       "        'proc. crypto 93,', '1994'],\n",
       "       [1, 'blum1993',\n",
       "        'avrim blum, merrick furst, michael kearns, and richard j. lipton.',\n",
       "        ..., 'cryptographic primitives based on hard learning problems.',\n",
       "        'crypto,', '1993'],\n",
       "       ...,\n",
       "       [1293, 'singer', 'robert e. schapire yoram singer.', ...,\n",
       "        'a system for multiclass multi-label text categorization.',\n",
       "        'unpublished manuscript,', '1998'],\n",
       "       [1293, 'singer', 'robert e. schapire yoram singer.', ...,\n",
       "        'improved boosting algorithms using confidence-rated predictions.',\n",
       "        None, None],\n",
       "       [1293, 'singer', 'robert e. schapire yoram singer.', ...,\n",
       "        'improved boosting algorithms using confidence-rated predictions.',\n",
       "        None, None]], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We're going to split the data into 100 folds. Using 10 folds is extremely slow\n",
    "in Python because of how slow Python's for loops are."
   ],
   "id": "9ff5af02253d403e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T06:17:31.507539Z",
     "start_time": "2024-10-17T06:17:30.260542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "n_splits = 100\n",
    "X_shuffled, y_shuffled = shuffle(X, y, random_state=42)\n",
    "X_splits = np.array_split(X, n_splits)\n",
    "y_splits = np.array_split(y, n_splits)\n",
    "\n",
    "folds = []\n",
    "for i in range(n_splits):\n",
    "    X_split_train, X_split_test, y_split_train, y_split_test = train_test_split(X_splits[i], y_splits[i], train_size=0.7) \n",
    "    folds.append((X_splits[i], y_splits[i], X_split_train, y_split_train, X_split_test, y_split_test))"
   ],
   "id": "ea0ac130ea4a1cc",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T06:17:32.940389Z",
     "start_time": "2024-10-17T06:17:32.936527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def train_distance_model(features, target, n_samples=100, epochs=10):\n",
    "    idx_of_matches, = np.where(target == 1)\n",
    "    matching_recods = features[idx_of_matches]\n",
    "    coreferent_values = [(val[3], val[9]) for val in matching_recods]\n",
    "    corpus = list(random.choices(coreferent_values, k=n_samples))\n",
    "    return LevenshteinLearner().fit(corpus, epochs)\n",
    "\n",
    "\n",
    "def train_svm(features, target):\n",
    "    model = LinearSVC()\n",
    "    model.fit(features, target)\n",
    "    return model"
   ],
   "id": "acc6a87596576c76",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, train the Levenshtein distance estimator using 100 random samples from\n",
    "the data over 10 epochs. "
   ],
   "id": "5b17db84d6edda0b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T06:21:40.566227Z",
     "start_time": "2024-10-17T06:17:36.012091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from jellyfish import levenshtein_distance\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def _title_levenshtein(values: tuple) -> tuple:\n",
    "    return (levenshtein_distance(values[3], values[9]),)\n",
    "\n",
    "\n",
    "def _title_learned_levenshtein(values: tuple) -> tuple:\n",
    "    return (distance_model.compute_distance(values[3], values[9]),)\n",
    "\n",
    "\n",
    "stats = []\n",
    "limit = 3\n",
    "max_count = limit * 8\n",
    "f = IntProgress(min=0, max=max_count)\n",
    "display(f)\n",
    "\n",
    "for idx, (X, y, X_train, y_train, X_test, y_test) in itertools.islice(enumerate(folds), limit):\n",
    "    distance_model = train_distance_model(X, y, 50)\n",
    "    title_train = list(map(_title_levenshtein, X_train))\n",
    "    f.value += 1\n",
    "    model = train_svm(title_train, y_train)\n",
    "    f.value += 1\n",
    "    print(\"trained SVM levenshtein #\", idx+1)\n",
    "    title_test = list(map(_title_levenshtein, X_test))\n",
    "    f.value += 1\n",
    "    prediction = model.predict(title_test)\n",
    "    f.value += 1\n",
    "    print(\"evaluated levenshtein #\", idx+1)\n",
    "\n",
    "    learned_title_train = list(map(_title_learned_levenshtein, X_train))\n",
    "    f.value += 1\n",
    "    learned_model = train_svm(learned_title_train, y_train)\n",
    "    f.value += 1\n",
    "    print(\"trained SVM learned-levenshtein #\", idx+1)\n",
    "    learned_title_test = list(map(_title_learned_levenshtein, X_test))\n",
    "    f.value += 1\n",
    "    learned_prediction = model.predict(learned_title_test)\n",
    "    f.value += 1\n",
    "    print(\"evaluated learned-levenshtein #\", idx+1)\n",
    "    \n",
    "    stats.append({\n",
    "        \"levenshtein precision\": precision_score(y_test, prediction),\n",
    "        \"levenshtein recall\": recall_score(y_test, prediction),\n",
    "        \"levenshtein f1\": f1_score(y_test, prediction),\n",
    "        \"learned levenshtein precision\": precision_score(y_test, learned_prediction),\n",
    "        \"learned levenshtein recall\": recall_score(y_test, learned_prediction),\n",
    "        \"learned levenshtein f1\": f1_score(y_test, learned_prediction),\n",
    "    })"
   ],
   "id": "f4232d883c8b2879",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntProgress(value=0, max=24)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c80a3eab4db64f6fbb543cbb3218c5be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged after 9 epochs\n",
      "trained SVM levenshtein # 1\n",
      "evaluated levenshtein # 1\n",
      "trained SVM learned-levenshtein # 1\n",
      "evaluated learned-levenshtein # 1\n",
      "converged after 7 epochs\n",
      "trained SVM levenshtein # 2\n",
      "evaluated levenshtein # 2\n",
      "trained SVM learned-levenshtein # 2\n",
      "evaluated learned-levenshtein # 2\n",
      "converged after 7 epochs\n",
      "trained SVM levenshtein # 3\n",
      "evaluated levenshtein # 3\n",
      "trained SVM learned-levenshtein # 3\n",
      "evaluated learned-levenshtein # 3\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:03:36.263442Z",
     "start_time": "2024-10-17T20:03:36.256450Z"
    }
   },
   "cell_type": "code",
   "source": "display(pl.DataFrame(stats))",
   "id": "9be33bd7c25d103a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (3, 6)\n",
       "┌────────────────┬────────────────┬────────────────┬───────────────┬───────────────┬───────────────┐\n",
       "│ levenshtein    ┆ levenshtein    ┆ levenshtein f1 ┆ learned       ┆ learned       ┆ learned       │\n",
       "│ precision      ┆ recall         ┆ ---            ┆ levenshtein   ┆ levenshtein   ┆ levenshtein   │\n",
       "│ ---            ┆ ---            ┆ f64            ┆ precision     ┆ recall        ┆ f1            │\n",
       "│ f64            ┆ f64            ┆                ┆ ---           ┆ ---           ┆ ---           │\n",
       "│                ┆                ┆                ┆ f64           ┆ f64           ┆ f64           │\n",
       "╞════════════════╪════════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
       "│ 1.0            ┆ 1.0            ┆ 1.0            ┆ 0.002001      ┆ 0.357143      ┆ 0.003979      │\n",
       "│ 1.0            ┆ 0.787986       ┆ 0.881423       ┆ 0.0           ┆ 0.0           ┆ 0.0           │\n",
       "│ 1.0            ┆ 0.763948       ┆ 0.86618        ┆ 0.0           ┆ 0.0           ┆ 0.0           │\n",
       "└────────────────┴────────────────┴────────────────┴───────────────┴───────────────┴───────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>levenshtein precision</th><th>levenshtein recall</th><th>levenshtein f1</th><th>learned levenshtein precision</th><th>learned levenshtein recall</th><th>learned levenshtein f1</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>1.0</td><td>1.0</td><td>1.0</td><td>0.002001</td><td>0.357143</td><td>0.003979</td></tr><tr><td>1.0</td><td>0.787986</td><td>0.881423</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>1.0</td><td>0.763948</td><td>0.86618</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T05:15:17.887945Z",
     "start_time": "2024-10-17T05:15:17.861433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stats = pl.DataFrame(stats)\n",
    "display(stats)\n",
    "display(stats.mean())"
   ],
   "id": "5d6e75d34086aff1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (10, 6)\n",
       "┌────────────────┬────────────────┬────────────────┬───────────────┬───────────────┬───────────────┐\n",
       "│ levenshtein    ┆ levenshtein    ┆ levenshtein f1 ┆ learned       ┆ learned       ┆ learned       │\n",
       "│ precision      ┆ recall         ┆ ---            ┆ levenshtein   ┆ levenshtein   ┆ levenshtein   │\n",
       "│ ---            ┆ ---            ┆ f64            ┆ precision     ┆ recall        ┆ f1            │\n",
       "│ f64            ┆ f64            ┆                ┆ ---           ┆ ---           ┆ ---           │\n",
       "│                ┆                ┆                ┆ f64           ┆ f64           ┆ f64           │\n",
       "╞════════════════╪════════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
       "│ 0.766539       ┆ 0.841559       ┆ 0.802299       ┆ 0.766539      ┆ 0.841559      ┆ 0.802299      │\n",
       "│ 0.758516       ┆ 0.836792       ┆ 0.795733       ┆ 0.758516      ┆ 0.836792      ┆ 0.795733      │\n",
       "│ 0.762889       ┆ 0.838194       ┆ 0.798771       ┆ 0.762889      ┆ 0.838194      ┆ 0.798771      │\n",
       "│ 0.770097       ┆ 0.843522       ┆ 0.805139       ┆ 0.770097      ┆ 0.843522      ┆ 0.805139      │\n",
       "│ 0.765259       ┆ 0.843803       ┆ 0.802614       ┆ 0.765259      ┆ 0.843803      ┆ 0.802614      │\n",
       "│ 0.763351       ┆ 0.846003       ┆ 0.802555       ┆ 0.763351      ┆ 0.846003      ┆ 0.802555      │\n",
       "│ 0.758167       ┆ 0.839832       ┆ 0.796912       ┆ 0.758167      ┆ 0.839832      ┆ 0.796912      │\n",
       "│ 0.764512       ┆ 0.846003       ┆ 0.803196       ┆ 0.764512      ┆ 0.846003      ┆ 0.803196      │\n",
       "│ 0.745201       ┆ 0.838429       ┆ 0.789071       ┆ 0.745201      ┆ 0.838429      ┆ 0.789071      │\n",
       "│ 0.764602       ┆ 0.851893       ┆ 0.805891       ┆ 0.764602      ┆ 0.851893      ┆ 0.805891      │\n",
       "└────────────────┴────────────────┴────────────────┴───────────────┴───────────────┴───────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>levenshtein precision</th><th>levenshtein recall</th><th>levenshtein f1</th><th>learned levenshtein precision</th><th>learned levenshtein recall</th><th>learned levenshtein f1</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.766539</td><td>0.841559</td><td>0.802299</td><td>0.766539</td><td>0.841559</td><td>0.802299</td></tr><tr><td>0.758516</td><td>0.836792</td><td>0.795733</td><td>0.758516</td><td>0.836792</td><td>0.795733</td></tr><tr><td>0.762889</td><td>0.838194</td><td>0.798771</td><td>0.762889</td><td>0.838194</td><td>0.798771</td></tr><tr><td>0.770097</td><td>0.843522</td><td>0.805139</td><td>0.770097</td><td>0.843522</td><td>0.805139</td></tr><tr><td>0.765259</td><td>0.843803</td><td>0.802614</td><td>0.765259</td><td>0.843803</td><td>0.802614</td></tr><tr><td>0.763351</td><td>0.846003</td><td>0.802555</td><td>0.763351</td><td>0.846003</td><td>0.802555</td></tr><tr><td>0.758167</td><td>0.839832</td><td>0.796912</td><td>0.758167</td><td>0.839832</td><td>0.796912</td></tr><tr><td>0.764512</td><td>0.846003</td><td>0.803196</td><td>0.764512</td><td>0.846003</td><td>0.803196</td></tr><tr><td>0.745201</td><td>0.838429</td><td>0.789071</td><td>0.745201</td><td>0.838429</td><td>0.789071</td></tr><tr><td>0.764602</td><td>0.851893</td><td>0.805891</td><td>0.764602</td><td>0.851893</td><td>0.805891</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "shape: (1, 6)\n",
       "┌────────────────┬────────────────┬────────────────┬───────────────┬───────────────┬───────────────┐\n",
       "│ levenshtein    ┆ levenshtein    ┆ levenshtein f1 ┆ learned       ┆ learned       ┆ learned       │\n",
       "│ precision      ┆ recall         ┆ ---            ┆ levenshtein   ┆ levenshtein   ┆ levenshtein   │\n",
       "│ ---            ┆ ---            ┆ f64            ┆ precision     ┆ recall        ┆ f1            │\n",
       "│ f64            ┆ f64            ┆                ┆ ---           ┆ ---           ┆ ---           │\n",
       "│                ┆                ┆                ┆ f64           ┆ f64           ┆ f64           │\n",
       "╞════════════════╪════════════════╪════════════════╪═══════════════╪═══════════════╪═══════════════╡\n",
       "│ 0.761913       ┆ 0.842603       ┆ 0.800218       ┆ 0.761913      ┆ 0.842603      ┆ 0.800218      │\n",
       "└────────────────┴────────────────┴────────────────┴───────────────┴───────────────┴───────────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>levenshtein precision</th><th>levenshtein recall</th><th>levenshtein f1</th><th>learned levenshtein precision</th><th>learned levenshtein recall</th><th>learned levenshtein f1</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.761913</td><td>0.842603</td><td>0.800218</td><td>0.761913</td><td>0.842603</td><td>0.800218</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:26:13.490990Z",
     "start_time": "2024-10-15T14:26:13.490677Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "294b2958ddc8d4e0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
