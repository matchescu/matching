{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9239db8823ba023",
   "metadata": {},
   "source": [
    "# Using Pre-trained Transformers for Matching\n",
    "\n",
    "Start out by declaring a few constants."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T09:46:12.491974Z",
     "start_time": "2025-03-24T09:46:10.674776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "MODELDIR = os.path.abspath(\"../../models\")\n",
    "\n",
    "BERT_MODEL_NAME = \"roberta-base\"\n",
    "LEFT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Abt.csv\")\n",
    "RIGHT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Buy.csv\")\n",
    "GROUND_TRUTH_PATH = os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\")"
   ],
   "id": "17fbc732bd2e7b2f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cusi/Source/github.com/matchescu/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next, extract entity references and the ground truth from an existing CSV dataset.\n",
    "The entity references are stored in an \"ID\" table."
   ],
   "id": "df91db57dcd9d9b1"
  },
  {
   "cell_type": "code",
   "id": "b9741bb63d0c5d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T09:46:12.546978Z",
     "start_time": "2025-03-24T09:46:12.496390Z"
    }
   },
   "source": [
    "from functools import partial\n",
    "from matchescu.extraction import (\n",
    "    RecordIdAdapter,\n",
    "    RecordExtraction,\n",
    "    single_record,\n",
    "    Traits,\n",
    ")\n",
    "from matchescu.data_sources import CsvDataSource\n",
    "from matchescu.reference_store.id_table import InMemoryIdTable\n",
    "from matchescu.typing import EntityReferenceIdentifier\n",
    "\n",
    "abt_traits = list(\n",
    "    Traits().int([\"id\"]).string([\"name\", \"description\"]).currency([\"price\"])\n",
    ")\n",
    "abt = CsvDataSource(LEFT_CSV_PATH, traits=abt_traits).read()\n",
    "buy_traits = list(\n",
    "    Traits()\n",
    "    .int([\"id\"])\n",
    "    .string([\"name\", \"description\", \"manufacturer\"])\n",
    "    .currency([\"price\"])\n",
    ")\n",
    "buy = CsvDataSource(RIGHT_CSV_PATH, traits=buy_traits).read()\n",
    "\n",
    "gt = set(\n",
    "    (\n",
    "        EntityReferenceIdentifier(id_abt, abt.name),\n",
    "        EntityReferenceIdentifier(id_buy, buy.name),\n",
    "    )\n",
    "    for id_abt, id_buy in pl.read_csv(\n",
    "        os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\"),\n",
    "        ignore_errors=True,\n",
    "    ).iter_rows()\n",
    ")\n",
    "\n",
    "\n",
    "def _id(record, source):\n",
    "    return EntityReferenceIdentifier(record[\"id\"], source)\n",
    "\n",
    "\n",
    "def load_data_source(data_source: CsvDataSource) -> None:\n",
    "    record_adapter = RecordIdAdapter(partial(_id, source=data_source.name))\n",
    "    extract_references = RecordExtraction(data_source, record_adapter, single_record)\n",
    "    for ref in extract_references():\n",
    "        id_table.put(ref)\n",
    "\n",
    "\n",
    "id_table = InMemoryIdTable()\n",
    "load_data_source(abt)\n",
    "load_data_source(buy)\n",
    "original_comparison_space_size = len(abt) * len(buy)\n",
    "print(\n",
    "    f\"total entity references: {len(id_table)}, original_comparison_space_size: {original_comparison_space_size}\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entity references: 2173, original_comparison_space_size: 1180452\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "d001811f44c60ae3",
   "metadata": {},
   "source": [
    "Next up, we create the comparison space.\n",
    "A __binary__ comparison space is a list of pairs of entity reference identifiers.\n",
    "The entity references identified in this way are deemed more suitable than others to match.\n",
    "The comparison space is generated through blocking and filtering."
   ]
  },
  {
   "cell_type": "code",
   "id": "970ed70d018355a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:09:19.730033Z",
     "start_time": "2025-03-24T10:09:16.692619Z"
    }
   },
   "source": [
    "from matchescu.comparison_filtering import is_cross_source_comparison\n",
    "from matchescu.blocking import TfIdfBlocker, SortedNeighborhoodBlocker, LSHBlocker\n",
    "from matchescu.csg import BinaryComparisonSpaceGenerator, BinaryComparisonSpaceEvaluator\n",
    "\n",
    "csg = (\n",
    "    BinaryComparisonSpaceGenerator()\n",
    "    .add_blocker(TfIdfBlocker(id_table, 0.23))\n",
    "    .add_blocker(SortedNeighborhoodBlocker(id_table, 50))\n",
    "    .add_blocker(LSHBlocker(id_table, 0.3))\n",
    "    .add_filter(is_cross_source_comparison)\n",
    ")\n",
    "comparison_space = csg()\n",
    "eval_cs = BinaryComparisonSpaceEvaluator(gt, original_comparison_space_size)\n",
    "metrics = eval_cs(comparison_space)\n",
    "print(metrics)\n",
    "print(\"comparison space size:\", len(comparison_space))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockingMetrics(pair_completeness=0.699179580674567, pair_quality=0.03277777777777778, reduction_ratio=0.9801770847099247)\n",
      "comparison space size: 23400\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "26298c7a5a35eea0",
   "metadata": {},
   "source": [
    "Next, we need to load a pretrained matcher. This requires training a model.\n",
    "We're using the [Ditto classifier](https://github.com/megagonlabs/ditto/tree/master/ditto_light).\n",
    "To train Ditto using a BERT model, see the `matchescu.matching.ml.ditto.train` module."
   ]
  },
  {
   "cell_type": "code",
   "id": "839f3e67bfdbc056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T09:51:14.643537Z",
     "start_time": "2025-03-24T09:51:12.716707Z"
    }
   },
   "source": [
    "from matchescu.matching.ml.ditto import DittoSimilarity\n",
    "\n",
    "matcher = DittoSimilarity(\n",
    "    AutoTokenizer.from_pretrained(BERT_MODEL_NAME),\n",
    "    model_dir=MODELDIR,\n",
    "    left_cols=(\"name\", \"description\", \"price\"),\n",
    "    right_cols=(\"name\", \"description\", \"manufacturer\", \"price\"),\n",
    ")\n",
    "matcher.load_pretrained(BERT_MODEL_NAME)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "26f4c8842c3d3685",
   "metadata": {},
   "source": "Finally, run the matcher and compute some metrics."
  },
  {
   "cell_type": "code",
   "id": "ac4da705115d12d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T10:09:16.628943Z",
     "start_time": "2025-03-24T09:51:18.056083Z"
    }
   },
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# comparison space ground truth\n",
    "csgt = [int(pair in gt) for pair in comparison_space]\n",
    "\n",
    "# run matching algorithm on comparison space\n",
    "pred = []\n",
    "for left, right in comparison_space:\n",
    "    pred.append(\n",
    "        int(matcher(id_table.get(left), id_table.get(right)) > matcher.match_threshold)\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"precision: %.2f, recall: %.2f, F1: %.2f\"\n",
    "    % (\n",
    "        precision_score(csgt, pred),\n",
    "        recall_score(csgt, pred),\n",
    "        f1_score(csgt, pred),\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.67, recall: 0.82, F1: 0.74\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "38fb980ef8d21698"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
