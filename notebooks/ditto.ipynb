{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Raw String Similarity Features\n",
    "\n",
    "The paper [@bilenko2002learning] outlines a process by which we can learn the\n",
    "edit distance between two strings using minimal training over pairs of\n",
    "coreferent strings.\n",
    "Coreferent strings are strings found in references to the same entity.\n",
    "The idea is to fine tune the algorithm that computes the string edit distance to\n",
    "the business domain where we perform entity resolution. By doing so we increase\n",
    "the chances of recognizing records that refer to the same entity more\n",
    "accurately.\n",
    "The paper also references an algorithm [@ristad1998learning] which learns to\n",
    "compute the Levenshtein distance between two strings from training data. The\n",
    "method is computationally intensive and other methods have superseded it.\n",
    "\n",
    "Another finding suggests that accuracy gains can be made by training the SVM\n",
    "kernel that performs entity resolution in a specific way. This notebook goes\n",
    "through that training procedure and compares the results using SVMs to those\n",
    "obtained using Logistic Regression."
   ],
   "id": "b9239db8823ba023"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%load_ext tensorboard",
   "id": "bf961183140bb4be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "\n",
    "BERT_MODEL_NAME = \"roberta-base\"\n",
    "LEFT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Abt.csv\")\n",
    "RIGHT_CSV_PATH = os.path.join(DATADIR, \"abt-buy\", \"Buy.csv\")\n",
    "GROUND_TRUTH_PATH = os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\")"
   ],
   "id": "9bcd2799fcf96fd9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matchescu.matching.extraction import Traits, CsvDataSource\n",
    "\n",
    "# set up abt extraction\n",
    "abt_traits = list(Traits().int([0]).string([1, 2]).currency([3]))\n",
    "abt = CsvDataSource(name=\"abt\", traits=abt_traits).read_csv(LEFT_CSV_PATH)\n",
    "# set up buy extraction\n",
    "buy_traits = list(Traits().int([0]).string([1, 2, 3]).currency([4]))\n",
    "buy = CsvDataSource(name=\"buy\", traits=buy_traits).read_csv(RIGHT_CSV_PATH)\n",
    "# set up ground truth\n",
    "gt = set(\n",
    "    pl.read_csv(\n",
    "        os.path.join(DATADIR, \"abt-buy\", \"abt_buy_perfectMapping.csv\"),\n",
    "        ignore_errors=True,\n",
    "    ).iter_rows()\n",
    ")\n",
    "\n",
    "def _id(row):\n",
    "    return row[0]"
   ],
   "id": "b9741bb63d0c5d05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's set up a couple of functions that will help us shortly.\n",
    "\n",
    "We need to be able to perform a k-fold split of the training/test data to\n",
    "reproduce the results for classic edit distance from the paper\n",
    "[@bilenko2002learning].\n",
    "\n",
    "We will use the Levenshtein distance between coreferent strings to train an\n",
    "SVM kernel and a Logistic regression model. We wouldn't be able to use an NB\n",
    "approach or the classic pattern matching here since those don't work with\n",
    "continuous feature values."
   ],
   "id": "d001811f44c60ae3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matchescu.matching.blocking import BlockEngine\n",
    "\n",
    "\n",
    "blocker = BlockEngine().add_source(abt, _id).add_source(buy, _id).tf_idf(0.25)\n",
    "blocker.filter_candidates_jaccard(0.6)\n",
    "blocker.update_candidate_pairs(False)\n",
    "metrics = blocker.calculate_metrics(gt)\n",
    "\n",
    "display(metrics)"
   ],
   "id": "970ed70d018355a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now let's set the stable global parameters:\n",
    "\n",
    "- the fold count (i.e. the number of folds we're going to take through the input data)\n",
    "- the models (i.e. a mapping of user-friendly model name to training function)"
   ],
   "id": "26298c7a5a35eea0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from matchescu.matching.ml.ditto._ditto_dataset import DittoDataset\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "ds = DittoDataset(\n",
    "    blocker,\n",
    "    _id,\n",
    "    _id,\n",
    "    gt,\n",
    "    tokenizer,\n",
    "    left_cols=(\"name\",\"description\",\"price\"),\n",
    "    right_cols=(\"name\",\"description\",\"manufacturer\",\"price\"),\n",
    "    size=1000,\n",
    ")"
   ],
   "id": "839f3e67bfdbc056",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the deduplication scenario, we want to both reproduce the findings of Milenko et al\n",
    "and test how logistic regression compares to SVM.\n",
    "\n",
    "We start by preparing a data deduplication dataframe."
   ],
   "id": "26f4c8842c3d3685"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from matchescu.matching.ml.ditto._ditto_module import DittoModel\n",
    "\n",
    "ditto = DittoModel(BERT_MODEL_NAME)\n",
    "ditto.run_training(ds, BERT_MODEL_NAME)"
   ],
   "id": "ac4da705115d12d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "%tensorboard --logdir ./logs",
   "id": "d4c5ac41f0e1149f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5ea7817a1cf6bb42",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
