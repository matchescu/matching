{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using Raw String Similarity Features\n",
    "\n",
    "The paper [@bilenko2002learning] outlines a process by which we can learn the\n",
    "edit distance between two strings using minimal training over pairs of\n",
    "coreferent strings.\n",
    "Coreferent strings are strings found in references to the same entity.\n",
    "The idea is to fine tune the algorithm that computes the string edit distance to\n",
    "the business domain where we perform entity resolution. By doing so we increase\n",
    "the chances of recognizing records that refer to the same entity more\n",
    "accurately.\n",
    "The paper also references an algorithm [@ristad1998learning] which learns to\n",
    "compute the Levenshtein distance between two strings from training data. The\n",
    "method is computationally intensive and other methods have superseded it.\n",
    "\n",
    "Another finding suggests that accuracy gains can be made by training the SVM\n",
    "kernel that performs entity resolution in a specific way. This notebook goes\n",
    "through that training procedure and compares the results using SVMs to those\n",
    "obtained using Logistic Regression."
   ],
   "id": "b9239db8823ba023"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T07:29:19.844849Z",
     "start_time": "2024-12-12T07:29:19.764660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from matchescu.matching.similarity import LevenshteinLearner\n",
    "\n",
    "\n",
    "DATADIR = os.path.abspath(\"../../data\")\n",
    "CSV_PATH = os.path.join(DATADIR, \"cora\", \"cora.csv\")"
   ],
   "id": "9bcd2799fcf96fd9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T07:29:21.094349Z",
     "start_time": "2024-12-12T07:29:21.080961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = (\n",
    "    pl.read_csv(CSV_PATH, has_header=False, ignore_errors=True)\n",
    "    .rename(\n",
    "        {\n",
    "            \"column_1\": \"id\",\n",
    "            \"column_3\": \"class\",\n",
    "            \"column_4\": \"author\",\n",
    "            \"column_5\": \"volume\",\n",
    "            \"column_6\": \"title\",\n",
    "            \"column_7\": \"institution\",\n",
    "            \"column_8\": \"venue\",\n",
    "            \"column_11\": \"year\",\n",
    "        }\n",
    "    )\n",
    "    .select(pl.col(\"id\", \"class\", \"author\", \"title\", \"venue\", \"year\"))\n",
    ")\n",
    "display(df)"
   ],
   "id": "b9741bb63d0c5d05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (1_293, 6)\n",
       "┌──────┬────────────────┬─────────────────────┬─────────────────────┬────────────────────┬─────────┐\n",
       "│ id   ┆ class          ┆ author              ┆ title               ┆ venue              ┆ year    │\n",
       "│ ---  ┆ ---            ┆ ---                 ┆ ---                 ┆ ---                ┆ ---     │\n",
       "│ i64  ┆ str            ┆ str                 ┆ str                 ┆ str                ┆ str     │\n",
       "╞══════╪════════════════╪═════════════════════╪═════════════════════╪════════════════════╪═════════╡\n",
       "│ 1    ┆ blum1993       ┆ avrim blum, merrick ┆ cryptographic       ┆ in pre-proceedings ┆ 1993    │\n",
       "│      ┆                ┆ furst, mic…         ┆ primitives based…   ┆ of crypto '…       ┆         │\n",
       "│ 2    ┆ blum1993       ┆ avrim blum, merrick ┆ cryptographic       ┆ proc. crypto 93,   ┆ 1994    │\n",
       "│      ┆                ┆ furst, mic…         ┆ primitives based…   ┆                    ┆         │\n",
       "│ 3    ┆ blum1993       ┆ a. blum, m. furst,  ┆ cryptographic       ┆ crypto,            ┆ 1993    │\n",
       "│      ┆                ┆ m. kearns, …        ┆ primitives based…   ┆                    ┆         │\n",
       "│ 4    ┆ blum1994       ┆ blum, a., furst,    ┆ weakly learning dnf ┆ proceedings of the ┆ (1994). │\n",
       "│      ┆                ┆ m., jackson, …      ┆ and charac…         ┆ 26th annual…       ┆         │\n",
       "│ 5    ┆ blum1994       ┆ blum, a., furst,    ┆ weakly learning dnf ┆ in proceedings of  ┆ (1994). │\n",
       "│      ┆                ┆ m., jackson, …      ┆ and charac…         ┆ the twenty-s…      ┆         │\n",
       "│ …    ┆ …              ┆ …                   ┆ …                   ┆ …                  ┆ …       │\n",
       "│ 1289 ┆ schapire1998   ┆ robert e. schapire  ┆ improved boosting   ┆ in proceedings of  ┆ 1998    │\n",
       "│      ┆                ┆ and yoram s…        ┆ algorithms u…       ┆ the eleventh…      ┆         │\n",
       "│ 1290 ┆ schapire       ┆ schapire, r. e.,    ┆ boosting the        ┆ null               ┆ (1998). │\n",
       "│      ┆                ┆ freund, y., b…      ┆ margin: a new exp…  ┆                    ┆         │\n",
       "│ 1291 ┆ schapire1998mm ┆ robert e. schapire  ┆ a system for        ┆ unpublished        ┆ 1998    │\n",
       "│      ┆                ┆ and yoram s…        ┆ multiclass multi-…  ┆ manuscript,        ┆         │\n",
       "│ 1292 ┆ singer         ┆ robert e. schapire  ┆ improved boosting   ┆ null               ┆ null    │\n",
       "│      ┆                ┆ yoram singe…        ┆ algorithms u…       ┆                    ┆         │\n",
       "│ 1293 ┆ singer         ┆ robert e. schapire  ┆ improved boosting   ┆ null               ┆ null    │\n",
       "│      ┆                ┆ yoram singe…        ┆ algorithms u…       ┆                    ┆         │\n",
       "└──────┴────────────────┴─────────────────────┴─────────────────────┴────────────────────┴─────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_293, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>class</th><th>author</th><th>title</th><th>venue</th><th>year</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;blum1993&quot;</td><td>&quot;avrim blum, merrick furst, mic…</td><td>&quot;cryptographic primitives based…</td><td>&quot;in pre-proceedings of crypto &#x27;…</td><td>&quot;1993&quot;</td></tr><tr><td>2</td><td>&quot;blum1993&quot;</td><td>&quot;avrim blum, merrick furst, mic…</td><td>&quot;cryptographic primitives based…</td><td>&quot;proc. crypto 93,&quot;</td><td>&quot;1994&quot;</td></tr><tr><td>3</td><td>&quot;blum1993&quot;</td><td>&quot;a. blum, m. furst, m. kearns, …</td><td>&quot;cryptographic primitives based…</td><td>&quot;crypto,&quot;</td><td>&quot;1993&quot;</td></tr><tr><td>4</td><td>&quot;blum1994&quot;</td><td>&quot;blum, a., furst, m., jackson, …</td><td>&quot;weakly learning dnf and charac…</td><td>&quot;proceedings of the 26th annual…</td><td>&quot;(1994).&quot;</td></tr><tr><td>5</td><td>&quot;blum1994&quot;</td><td>&quot;blum, a., furst, m., jackson, …</td><td>&quot;weakly learning dnf and charac…</td><td>&quot;in proceedings of the twenty-s…</td><td>&quot;(1994).&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1289</td><td>&quot;schapire1998&quot;</td><td>&quot;robert e. schapire and yoram s…</td><td>&quot;improved boosting algorithms u…</td><td>&quot;in proceedings of the eleventh…</td><td>&quot;1998&quot;</td></tr><tr><td>1290</td><td>&quot;schapire&quot;</td><td>&quot;schapire, r. e., freund, y., b…</td><td>&quot;boosting the margin: a new exp…</td><td>null</td><td>&quot;(1998).&quot;</td></tr><tr><td>1291</td><td>&quot;schapire1998mm&quot;</td><td>&quot;robert e. schapire and yoram s…</td><td>&quot;a system for multiclass multi-…</td><td>&quot;unpublished manuscript,&quot;</td><td>&quot;1998&quot;</td></tr><tr><td>1292</td><td>&quot;singer&quot;</td><td>&quot;robert e. schapire yoram singe…</td><td>&quot;improved boosting algorithms u…</td><td>null</td><td>null</td></tr><tr><td>1293</td><td>&quot;singer&quot;</td><td>&quot;robert e. schapire yoram singe…</td><td>&quot;improved boosting algorithms u…</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T07:29:29.677431Z",
     "start_time": "2024-12-12T07:29:23.505861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "records = list(df.iter_rows(named=True))\n",
    "dedupe_data = []\n",
    "y = []\n",
    "for i, left_record in enumerate(records):\n",
    "    for j, right_record in enumerate(records, i + 1):\n",
    "        lclass, rclass = left_record[\"class\"], right_record[\"class\"]\n",
    "        row = {f\"{k}_left\": v for k, v in left_record.items()}\n",
    "        row.update({f\"{k}_right\": v for k, v in right_record.items()})\n",
    "        dedupe_data.append(row)\n",
    "        y.append(int(lclass == rclass))\n",
    "X = pl.DataFrame(dedupe_data).to_numpy()\n",
    "y = np.array(y)"
   ],
   "id": "7cfc4cd52f58e38c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's set up a couple of functions that will help us shortly.\n",
    "\n",
    "We need to be able to perform a k-fold split of the training/test data to\n",
    "reproduce the results for classic edit distance from the paper\n",
    "[@bilenko2002learning].\n",
    "\n",
    "We will use the Levenshtein distance between coreferent strings to train an\n",
    "SVM kernel and a Logistic regression model. We wouldn't be able to use an NB\n",
    "approach or the classic pattern matching here since those don't work with\n",
    "continuous feature values."
   ],
   "id": "d001811f44c60ae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T08:17:24.676372Z",
     "start_time": "2024-12-12T08:17:24.670056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jellyfish import levenshtein_distance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def generate_k_folds(n_splits: int) -> list[tuple]:\n",
    "    kf = KFold(n_splits)\n",
    "    result = []\n",
    "    for (train_idx, test_idx) in kf.split(X, y):\n",
    "        result.append((X[train_idx], y[train_idx], X[test_idx], y[test_idx]))\n",
    "    return result\n",
    "\n",
    "\n",
    "def train_svm(features, target):\n",
    "    svm_kernel = LinearSVC()\n",
    "    svm_kernel.fit(features, target)\n",
    "    return svm_kernel\n",
    "\n",
    "\n",
    "def train_regression(features, target):\n",
    "    log_regression = LogisticRegression()\n",
    "    log_regression.fit(features, target)\n",
    "    return log_regression\n",
    "\n",
    "\n",
    "def _safe_str(value) -> str:\n",
    "    if value is None:\n",
    "        return \"\"\n",
    "    if not isinstance(value, str):\n",
    "        return str(value)\n",
    "    return value\n",
    "\n",
    "def compute_distances(values: tuple) -> tuple:\n",
    "    values = tuple(map(_safe_str, values))\n",
    "    return (\n",
    "        levenshtein_distance(values[2], values[8]),\n",
    "        levenshtein_distance(values[3], values[9]),\n",
    "        levenshtein_distance(values[4], values[10]),\n",
    "    )"
   ],
   "id": "970ed70d018355a7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The main part of the notebook is to split the data, train SVM, train logistic\n",
    "regression, run predictions for both models and compare results."
   ],
   "id": "9ff5af02253d403e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T08:31:40.392300Z",
     "start_time": "2024-12-12T08:17:28.866602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "fold_count = int(input(\"folds:\"))\n",
    "stats = []\n",
    "folds = generate_k_folds(fold_count)\n",
    "\n",
    "models = {\n",
    "    \"svm\": train_svm,\n",
    "    \"regression\": train_regression\n",
    "}\n",
    "\n",
    "for idx, (X_train, y_train, X_test, y_test) in enumerate(folds, start=1):\n",
    "    title_train = list(map(compute_distances, X_train))\n",
    "    trained_models = {\n",
    "        model: train(title_train, y_train)\n",
    "        for model, train in models.items()\n",
    "    }\n",
    "    print(\"trained on fold #\", idx)\n",
    "\n",
    "    title_test = list(map(compute_distances, X_test))\n",
    "    for model_name, model in trained_models.items():\n",
    "        prediction = model.predict(title_test)\n",
    "        stats.append(\n",
    "            {\n",
    "                \"model\": model_name,\n",
    "                \"precision\": precision_score(y_test, prediction),\n",
    "                \"recall\": recall_score(y_test, prediction),\n",
    "                \"f1\": f1_score(y_test, prediction),\n",
    "            }\n",
    "        )\n",
    "    print(\"evaluated fold #\", idx)\n",
    "stats = pl.DataFrame(stats)\n",
    "display(stats)"
   ],
   "id": "f4232d883c8b2879",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained on fold # 1\n",
      "evaluated fold # 1\n",
      "trained on fold # 2\n",
      "evaluated fold # 2\n",
      "trained on fold # 3\n",
      "evaluated fold # 3\n",
      "trained on fold # 4\n",
      "evaluated fold # 4\n",
      "trained on fold # 5\n",
      "evaluated fold # 5\n",
      "trained on fold # 6\n",
      "evaluated fold # 6\n",
      "trained on fold # 7\n",
      "evaluated fold # 7\n",
      "trained on fold # 8\n",
      "evaluated fold # 8\n",
      "trained on fold # 9\n",
      "evaluated fold # 9\n",
      "trained on fold # 10\n",
      "evaluated fold # 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "shape: (20, 4)\n",
       "┌────────────┬───────────┬──────────┬──────────┐\n",
       "│ model      ┆ precision ┆ recall   ┆ f1       │\n",
       "│ ---        ┆ ---       ┆ ---      ┆ ---      │\n",
       "│ str        ┆ f64       ┆ f64      ┆ f64      │\n",
       "╞════════════╪═══════════╪══════════╪══════════╡\n",
       "│ svm        ┆ 0.935116  ┆ 0.338898 ┆ 0.497497 │\n",
       "│ regression ┆ 0.941388  ┆ 0.328666 ┆ 0.487227 │\n",
       "│ svm        ┆ 0.865943  ┆ 0.902752 ┆ 0.883965 │\n",
       "│ regression ┆ 0.870763  ┆ 0.879817 ┆ 0.875266 │\n",
       "│ svm        ┆ 0.789357  ┆ 0.848967 ┆ 0.818078 │\n",
       "│ …          ┆ …         ┆ …        ┆ …        │\n",
       "│ regression ┆ 0.664469  ┆ 0.893884 ┆ 0.76229  │\n",
       "│ svm        ┆ 0.636447  ┆ 0.82921  ┆ 0.720152 │\n",
       "│ regression ┆ 0.644112  ┆ 0.790104 ┆ 0.709677 │\n",
       "│ svm        ┆ 0.896607  ┆ 0.816977 ┆ 0.854942 │\n",
       "│ regression ┆ 0.945768  ┆ 0.808636 ┆ 0.871842 │\n",
       "└────────────┴───────────┴──────────┴──────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>precision</th><th>recall</th><th>f1</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;svm&quot;</td><td>0.935116</td><td>0.338898</td><td>0.497497</td></tr><tr><td>&quot;regression&quot;</td><td>0.941388</td><td>0.328666</td><td>0.487227</td></tr><tr><td>&quot;svm&quot;</td><td>0.865943</td><td>0.902752</td><td>0.883965</td></tr><tr><td>&quot;regression&quot;</td><td>0.870763</td><td>0.879817</td><td>0.875266</td></tr><tr><td>&quot;svm&quot;</td><td>0.789357</td><td>0.848967</td><td>0.818078</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;regression&quot;</td><td>0.664469</td><td>0.893884</td><td>0.76229</td></tr><tr><td>&quot;svm&quot;</td><td>0.636447</td><td>0.82921</td><td>0.720152</td></tr><tr><td>&quot;regression&quot;</td><td>0.644112</td><td>0.790104</td><td>0.709677</td></tr><tr><td>&quot;svm&quot;</td><td>0.896607</td><td>0.816977</td><td>0.854942</td></tr><tr><td>&quot;regression&quot;</td><td>0.945768</td><td>0.808636</td><td>0.871842</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T08:48:27.585010Z",
     "start_time": "2024-12-12T08:48:27.579927Z"
    }
   },
   "cell_type": "code",
   "source": "display(stats.group_by(\"model\").mean())",
   "id": "5d6e75d34086aff1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shape: (2, 4)\n",
       "┌────────────┬───────────┬──────────┬──────────┐\n",
       "│ model      ┆ precision ┆ recall   ┆ f1       │\n",
       "│ ---        ┆ ---       ┆ ---      ┆ ---      │\n",
       "│ str        ┆ f64       ┆ f64      ┆ f64      │\n",
       "╞════════════╪═══════════╪══════════╪══════════╡\n",
       "│ svm        ┆ 0.765938  ┆ 0.828311 ┆ 0.77241  │\n",
       "│ regression ┆ 0.779555  ┆ 0.79966  ┆ 0.766207 │\n",
       "└────────────┴───────────┴──────────┴──────────┘"
      ],
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>model</th><th>precision</th><th>recall</th><th>f1</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;svm&quot;</td><td>0.765938</td><td>0.828311</td><td>0.77241</td></tr><tr><td>&quot;regression&quot;</td><td>0.779555</td><td>0.79966</td><td>0.766207</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook reproduces the original findings in [@bilenko2002learning] to a\n",
    "sufficient degree to inspire confidence in the other results observed here.\n",
    "Using the Levenshtein distance instead of patterns or match/non-match semantics\n",
    "seems to dramatically improve both the precision and the recall of the matching\n",
    "process for both SVMs and Logistic Regression.\n",
    "The difference in performance between the two is negligible.\n",
    "\n",
    "On one hand, we see that using more expressive feature values improves the\n",
    "match performance.\n",
    "This is akin to having a stronger signal and the conclusion is not surprising\n",
    "at all.\n",
    "\n",
    "On the other hand we see that the models still need a lot of data preprocessing\n",
    "to function correctly. They:\n",
    "\n",
    "* can only compare apples to apples\n",
    "* do not transfer any of the learning to a new comparison of pears to pears\n",
    "* are reasonably powerful only if data has been previously cleaned\n",
    "\n",
    "Note that these models are still variations on the Fellegi-Sunter model in that\n",
    "they only manipulate probability distributions using polynomials.\n",
    "Neither SVMs (the construction of the kernel is probabilistic) nor Logistic\n",
    "Regression (the sigmoid function emulates probabilities) represent breakthroughs\n",
    "from what we've seen so far.\n",
    "The one thing they do in addition to more classical implementations of the F-S\n",
    "model is that they work with continuous valued input features.\n"
   ],
   "id": "dcf60fa97d0a0d86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cb39889b6e3386e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
